{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 'val' # 'train' or 'val'\n",
    "LIST_DIR = 'data/list'\n",
    "DATASET_DIR = 'data/sets/TMGN_1814'\n",
    "DATASET_DIR_MAP = f'{DATASET_DIR}/{SPLIT}/map_256'\n",
    "DATASET_DIR_SAT = f'{DATASET_DIR}/{SPLIT}/rs_256'\n",
    "\n",
    "TARGET_ZOOM_MIN = 14  # 你可以根据需要修改这个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist_or_create(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def clean_up_side_image(dir_path1, dir_path2):\n",
    "    target_set = set(os.listdir(dir_path1))\n",
    "    for img_name in os.listdir(dir_path2):\n",
    "        if img_name in target_set:\n",
    "            continue\n",
    "        else:\n",
    "            os.remove(os.path.join(dir_path2, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_filenames_map = os.listdir(DATASET_DIR_MAP)\n",
    "list_filenames_sat = os.listdir(DATASET_DIR_SAT)\n",
    "\n",
    "print(\"map:\",len(list_filenames_map))\n",
    "print(\"sat:\",len(list_filenames_sat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "INPUT_DIR = f'{DATASET_DIR}/{SPLIT}/map_512'\n",
    "OUTPUT_DIR = f'{DATASET_DIR}/{SPLIT}/map_256_cv2'\n",
    "exist_or_create(OUTPUT_DIR)\n",
    "\n",
    "for filename in tqdm(list_filenames_map):\n",
    "    # 检查文件是否为 PNG 图像\n",
    "    if filename.endswith('.png'):\n",
    "        # 读取图像\n",
    "        parent_img = cv2.imread(os.path.join(DATASET_DIR_MAP, filename), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # 检查图像是否为 512 大小\n",
    "        if parent_img.shape[0] == 512 and parent_img.shape[1] == 512:\n",
    "            # 转换图像大小为 256\n",
    "            resized_img = cv2.resize(parent_img, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            # 保存转换后的图像\n",
    "            cv2.imwrite(os.path.join(OUTPUT_DIR, filename), resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import re\n",
    "\n",
    "def process_filename(filename):\n",
    "    # 使用正则表达式匹配文件名中的特定部分\n",
    "    match = re.match(r\"(\\d+_\\d+_\\d+)_.*\\.png\", filename)\n",
    "    if match:\n",
    "        # 如果匹配成功，取出匹配的部分\n",
    "        new_filename = match.group(1)\n",
    "        # 拼接成新的文件名\n",
    "        new_filename += \".png\"\n",
    "        return new_filename\n",
    "\n",
    "dir_output = 'data/val/refmap-level-val-s4c-1816/val/class'\n",
    "dir_image = \"data/val/refmap-level-val-s4c-1816/val/step--0\"\n",
    "list_filenames = os.listdir(dir_image)\n",
    "\n",
    "for filename in tqdm(list_filenames):\n",
    "    filename_clean = process_filename(filename)\n",
    "    # 检查文件是否为 PNG 图像\n",
    "    if filename.endswith('.png'):\n",
    "        # 读取图像\n",
    "        if filename.endswith('samples.png'):\n",
    "            dir_copy = os.path.join(dir_image, 'samples')\n",
    "        elif filename.endswith('source.png'):\n",
    "            dir_copy = os.path.join(dir_image, 'source')\n",
    "        elif filename.endswith('target.png'):\n",
    "            dir_copy = os.path.join(dir_image, 'target')\n",
    "        elif filename.endswith('ref_scale.png'):\n",
    "            dir_copy = os.path.join(dir_image, 'ref_scale')\n",
    "\n",
    "        if not os.path.exists(dir_copy):\n",
    "            os.makedirs(dir_copy)\n",
    "\n",
    "        shutil.copy(os.path.join(dir_image, filename), os.path.join(dir_copy, filename_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output = 'data/val/refmap-level-val-s4c-1816/val/level'\n",
    "dir_image = \"data/val/refmap-level-val-s4c-1816/val/class\"\n",
    "\n",
    "list_dirs = os.listdir(dir_image)\n",
    "for dir_name in list_dirs:\n",
    "    print(dir_name)\n",
    "    dir_class = os.path.join(dir_image, dir_name)\n",
    "    list_filenames = os.listdir(dir_class)\n",
    "    for filename in tqdm(list_filenames):\n",
    "        # 检查文件是否为 PNG 图像\n",
    "        if filename.endswith('.png'):\n",
    "            for l in range(14,18):\n",
    "                if filename.startwith(l):\n",
    "                    dir_copy = os.path.join(dir_output, dir_name, str(l))\n",
    "                    if not os.path.exists(dir_copy):\n",
    "                        os.makedirs(dir_copy)\n",
    "                    shutil.copy(os.path.join(dir_image, filename), os.path.join(dir_copy, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (135000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from tile_name_calc import get_filename_parent_tile_scale\n",
    "\n",
    "SPLIT = 'train'\n",
    "SCALE = 4\n",
    "LIST_DIR = 'data/sets/list'\n",
    "DATASET_DIR = 'data/sets/TMGN_1814_source'\n",
    "DATA_LIST = f'{LIST_DIR}/{SPLIT}_file_data_1816seq.csv'\n",
    "INPUT_DIR = f'{DATASET_DIR}/{SPLIT}/map_256_source'\n",
    "COPY_DIR = f'{DATASET_DIR}/{SPLIT}/map_256'\n",
    "OUTPUT_DIR = f'{DATASET_DIR}/{SPLIT}/ref_{SCALE}_256'\n",
    "exist_or_create(COPY_DIR)\n",
    "exist_or_create(OUTPUT_DIR)\n",
    "\n",
    "zoom_scale = int(math.sqrt(SCALE))\n",
    "df_filenames_parent = pd.read_csv(DATA_LIST)\n",
    "print(zoom_scale, df_filenames_parent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0014f56259d44399a856a4e63ceda51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/135000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 遍历每一行，找出需要的文件\n",
    "for _, row in tqdm(df_filenames_parent.iterrows(), total=df_filenames_parent.shape[0], desc='Processing'):\n",
    "    filename = row['filename']\n",
    "    parent_filename = row['parent_filename']\n",
    "    position = row['position']\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    if os.path.exists(os.path.join(INPUT_DIR, filename)):\n",
    "        shutil.copyfile(os.path.join(INPUT_DIR, filename), os.path.join(COPY_DIR, filename))\n",
    "        parent_filename, x, y, size = get_filename_parent_tile_scale(filename, zoom_scale=zoom_scale)\n",
    "\n",
    "        if not os.path.exists(os.path.join(INPUT_DIR, parent_filename)):\n",
    "            print(f'Parent file {parent_filename} not found')\n",
    "            continue\n",
    "\n",
    "        # 读取图像\n",
    "        parent_img = cv2.imread(os.path.join(INPUT_DIR, parent_filename), cv2.IMREAD_UNCHANGED)\n",
    "        cropped_img = parent_img[y:y + size, x:x + size]\n",
    "        resized_img = cv2.resize(cropped_img, (parent_img.shape[0], parent_img.shape[1]), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # 保存图像\n",
    "        cv2.imwrite(os.path.join(OUTPUT_DIR, f'{filename}'), resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tile_name_calc import get_filename_parent_tile_scale\n",
    "\n",
    "SPLIT = 'train'\n",
    "SCALE = 4\n",
    "LIST_DIR = 'data/list'\n",
    "DATASET_DIR = 'data/sets/TMGN_1814_SOURCE'\n",
    "DATA_LIST = f'{LIST_DIR}/{SPLIT}_file_data_scale-{SCALE}-256.csv'\n",
    "SOURCE_DIR = f'{DATASET_DIR}/{SPLIT}/map_256_source'\n",
    "INPUT_DIR = f'{DATASET_DIR}/{SPLIT}/map_256'\n",
    "OUTPUT_DIR = f'{DATASET_DIR}/{SPLIT}/ref_{SCALE}_256'\n",
    "\n",
    "exist_or_create(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def get_crop_coordinates(x_start, y_start, img_size, position):\n",
    "    # 根据 position 计算裁剪区域的左上角坐标\n",
    "    if position == 'top_left':\n",
    "        x, y = x_start, y_start\n",
    "    elif position == 'top_right':\n",
    "        x, y = x_start + img_size // 2, y_start\n",
    "    elif position == 'bottom_left':\n",
    "        x, y = x_start, y_start + img_size // 2\n",
    "    elif position == 'bottom_right':\n",
    "        x, y = x_start + img_size // 2, y_start + img_size // 2\n",
    "\n",
    "    return x, y, img_size // 2\n",
    "\n",
    "def process_batch(batch):\n",
    "    source = batch.iloc[0]['filename']\n",
    "    target = batch.iloc[-1]['parent_filename']\n",
    "    positions = batch['position'].tolist()\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    if os.path.exists(os.path.join(INPUT_DIR, source)) and os.path.exists(os.path.join(SOURCE_DIR, target)):\n",
    "        # 读取图像\n",
    "        img = cv2.imread(os.path.join(SOURCE_DIR, target), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        x, y = 0, 0\n",
    "        img_size = img.shape[0]  # Assuming the image is square\n",
    "\n",
    "        positions.reverse()  # Reverse the list to crop the image from the bottom right corner\n",
    "\n",
    "        # 计算所有的裁剪坐标\n",
    "        for position in positions:\n",
    "            x, y, img_size = get_crop_coordinates(x, y, img_size, position)\n",
    "            #print(x, y, img_size)\n",
    "\n",
    "        # 使用最终的裁剪坐标裁剪图像\n",
    "        cropped_img = img[y:y+img_size, x:x+img_size]\n",
    "\n",
    "        # 放大图像\n",
    "        resized_img = cv2.resize(cropped_img, (img.shape[0], img.shape[1]), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        # 保存图像\n",
    "        cv2.imwrite(os.path.join(OUTPUT_DIR, f'{source}'), resized_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filenames_parent = pd.read_csv(DATA_LIST)\n",
    "zoom_scale = int(math.sqrt(SCALE))\n",
    "# 初始化一个空的批次\n",
    "batch_list = []\n",
    "\n",
    "# 遍历每一行，找出需要的文件\n",
    "for index in df_filenames_parent.index:\n",
    "    # 将行添加到批次中\n",
    "    row = df_filenames_parent.loc[index]\n",
    "    batch_list.append(row)\n",
    "\n",
    "    # 如果批次的大小达到了 zoom_scale，就处理批次\n",
    "    if len(batch_list) == zoom_scale:\n",
    "        batch = pd.DataFrame(batch_list, columns=df_filenames_parent.columns)\n",
    "        process_batch(batch)\n",
    "        # 清空批次，以便开始下一个批次\n",
    "        batch_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'data/sets/TMGN_1814_SOURCE/train/map_256'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtile_name_calc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_filename_parent_tiles, get_filename_parent_tiles_scale\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_DIR\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      5\u001b[0m         parent_filenames, positions \u001b[38;5;241m=\u001b[39m get_filename_parent_tiles_scale(filename, SCALE)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'data/sets/TMGN_1814_SOURCE/train/map_256'"
     ]
    }
   ],
   "source": [
    "from tile_name_calc import get_filename_parent_tiles, get_filename_parent_tiles_scale\n",
    "\n",
    "for filename in tqdm(os.listdir(INPUT_DIR)):\n",
    "    if filename.endswith('.png'):\n",
    "        parent_filenames, positions = get_filename_parent_tiles_scale(filename, SCALE)\n",
    "        current_filename = filename\n",
    "        parent_list = []\n",
    "        for parent_filename, position in zip(parent_filenames, positions):\n",
    "            parent_list.append([current_filename, parent_filename, position])\n",
    "            current_filename = parent_filename\n",
    "        parent_batch = pd.DataFrame(parent_list, columns=['filename', 'parent_filename', 'position'])\n",
    "        process_batch(parent_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def convert_jpg_to_png(jpg_filepath, png_filepath):\n",
    "    # 读取 JPG 图像\n",
    "    img = cv2.imread(jpg_filepath)\n",
    "\n",
    "    # 保存为 PNG 格式\n",
    "    cv2.imwrite(png_filepath, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f584f09db84a4bccb9d6f3001b7a5747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e43bdf4865409fa11870d4bebcc6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1ab2b13ddf49408fa69788c0125ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc46f29b3d94d99a998ccf48a4b2bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed98b16f5b35420a8e8d12dcedb8facb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7ec61d861e4c9caa48cc075d8f9a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATASET_DIR = '/mnt/runtime/scx/sgdm-data/datasets/MLMG/CN_dataset/'\n",
    "\n",
    "path_source = os.path.join(DATASET_DIR, \"testA\")\n",
    "path_target = os.path.join(DATASET_DIR, \"sgdm\", \"rs_256\")\n",
    "path_csv = os.path.join(DATASET_DIR, \"sgdm\", \"tilelist_18_15.csv\")\n",
    "\n",
    "os.makedirs(path_target, exist_ok=True)\n",
    "\n",
    "tilenames_list = []\n",
    "\n",
    "# 遍历原始路径下的所有文件\n",
    "for dirpath, dirnames, filenames in os.walk(path_source):\n",
    "    for filename in tqdm(filenames):\n",
    "        # 检查文件是否为.png文件\n",
    "        # if filename.endswith(\".png\"):\n",
    "        #     # 获取文件的完整原始路径\n",
    "        #     full_path = os.path.join(dirpath, filename)\n",
    "\n",
    "        #     # 生成新的文件名：将路径中的斜杠替换为下划线\n",
    "        #     relative_path = os.path.relpath(full_path, path_source)  # 获取相对于原始路径的相对路径\n",
    "        #     new_filename = relative_path.replace(os.sep, '_')\n",
    "        #     tilenames_list.append(os.path.splitext(new_filename)[0])\n",
    "\n",
    "        #     # 获取文件的新路径\n",
    "        #     new_full_path = os.path.join(path_target, new_filename)\n",
    "\n",
    "        #     # 复制文件到新路径\n",
    "        #     shutil.copy(full_path, new_full_path)\n",
    "\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # 获取文件的完整原始路径\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            tilenames_list.append(os.path.splitext(filename)[0])\n",
    "            new_filename = filename.replace(\".jpg\", \".png\")\n",
    "            new_full_path = os.path.join(path_target, new_filename)\n",
    "\n",
    "            convert_jpg_to_png(full_path, new_full_path)\n",
    "\n",
    "        elif filename.endswith(\".png\"):\n",
    "            tilenames_list.append(os.path.splitext(filename)[0])\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            new_full_path = os.path.join(path_target, filename)\n",
    "\n",
    "            shutil.copy(full_path, new_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个DataFrame\n",
    "df = pd.DataFrame(tilenames_list, columns=['tilename'])\n",
    "\n",
    "# 对DataFrame进行排序\n",
    "df = df.sort_values(by='tilename')\n",
    "\n",
    "# 确保CSV文件所在的目录存在\n",
    "os.makedirs(os.path.dirname(path_csv), exist_ok=True)\n",
    "\n",
    "# 将DataFrame导出为CSV文件\n",
    "df.to_csv(path_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818c5417c9ae43ba8aceb9013450a509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/scx/project/GEN/Generate/SGDM/data/datasets/MLMG/CN_dataset/sgdm/tilelist_18_15.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         tilename \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m         df_tilenames\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df_tilenames)] \u001b[38;5;241m=\u001b[39m [tilename]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mdf_tilenames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/scx/project/GEN/Generate/SGDM/data/datasets/MLMG/CN_dataset/sgdm/tilelist_18_15.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATASET_DIR = '/home/scx/project/GEN/Generate/SGDM/data/datasets/MLMG/CN_dataset/sgdm/'\n",
    "\n",
    "path_source = os.path.join(DATASET_DIR, \"map_256\")\n",
    "path_csv = os.path.join(DATASET_DIR, \"tilelist_18_15.csv\")\n",
    "\n",
    "df_tilenames = pd.DataFrame(columns=['tilename'])\n",
    "\n",
    "for filename in tqdm(os.listdir(path_source)):\n",
    "    if filename.endswith('.png'):\n",
    "        tilename = filename.split('.')[0]\n",
    "        df_tilenames.loc[len(df_tilenames)] = [tilename]\n",
    "\n",
    "df_tilenames.to_csv(path_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_tiles(xtile, ytile, zoom):\n",
    "    return [(xtile * 2, ytile * 2, zoom + 1),\n",
    "            (xtile * 2 + 1, ytile * 2, zoom + 1),\n",
    "            (xtile * 2, ytile * 2 + 1, zoom + 1),\n",
    "            (xtile * 2 + 1, ytile * 2 + 1, zoom + 1)]\n",
    "\n",
    "def get_filename_sub_tile(filename):\n",
    "    # 解析文件名\n",
    "    parts = filename.split('_')\n",
    "    z = int(parts[0])\n",
    "    x = int(parts[1])\n",
    "    y = int(parts[2].split('.')[0])  # 注意这里我们需要去除文件扩展名\n",
    "\n",
    "    # 获取下级瓦片\n",
    "    subtiles = get_sub_tiles(x, y, z)\n",
    "\n",
    "    # 将下级瓦片转换为文件名格式\n",
    "    subtile_filenames = [f\"{z}_{x}_{y}.png\" for (x, y, z) in subtiles]\n",
    "\n",
    "    return subtile_filenames\n",
    "\n",
    "def get_filename_sub_tiles(filename, target_zoom=18):\n",
    "    # 解析文件名\n",
    "    parts = filename.split('_')\n",
    "    z = int(parts[0])\n",
    "\n",
    "    # 创建一个列表来保存结果，并将当前瓦片添加到结果中\n",
    "    result = [filename]\n",
    "\n",
    "    # 如果当前缩放级别还没有达到目标缩放级别，获取下级瓦片并递归调用此函数\n",
    "    if z < target_zoom:\n",
    "        subtile_filenames = get_filename_sub_tile(filename)\n",
    "        for subtile_filename in subtile_filenames:\n",
    "            result.extend(get_filename_sub_tiles(subtile_filename, target_zoom))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "FILE_DIR = '/home/scx/project/GEN/Generate/SGDM/data/test/refmap-level-test-range-s2'\n",
    "INPUT_DIR = f'{FILE_DIR}/target'\n",
    "OUTPUT_DIR = f'{FILE_DIR}/recursive/14_8189_5447/target'\n",
    "FILENAME = '14_8189_5447.png'\n",
    "\n",
    "exist_or_create(OUTPUT_DIR)\n",
    "\n",
    "tilenames_list = get_filename_sub_tiles(FILENAME, 18)\n",
    "tilenames_list.remove(FILENAME)\n",
    "for tilename in tilenames_list:\n",
    "    assert os.path.exists(os.path.join(INPUT_DIR, tilename)), f\"File {tilename} not found\"\n",
    "    shutil.copy(os.path.join(INPUT_DIR, tilename), os.path.join(OUTPUT_DIR, tilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14_8189_5447.png', '15_16378_10894.png', '16_32756_21788.png', '17_65512_43576.png', '18_131024_87152.png', '18_131025_87152.png', '18_131024_87153.png', '18_131025_87153.png', '17_65513_43576.png', '18_131026_87152.png', '18_131027_87152.png', '18_131026_87153.png', '18_131027_87153.png', '17_65512_43577.png', '18_131024_87154.png', '18_131025_87154.png', '18_131024_87155.png', '18_131025_87155.png', '17_65513_43577.png', '18_131026_87154.png', '18_131027_87154.png', '18_131026_87155.png', '18_131027_87155.png', '16_32757_21788.png', '17_65514_43576.png', '18_131028_87152.png', '18_131029_87152.png', '18_131028_87153.png', '18_131029_87153.png', '17_65515_43576.png', '18_131030_87152.png', '18_131031_87152.png', '18_131030_87153.png', '18_131031_87153.png', '17_65514_43577.png', '18_131028_87154.png', '18_131029_87154.png', '18_131028_87155.png', '18_131029_87155.png', '17_65515_43577.png', '18_131030_87154.png', '18_131031_87154.png', '18_131030_87155.png', '18_131031_87155.png', '16_32756_21789.png', '17_65512_43578.png', '18_131024_87156.png', '18_131025_87156.png', '18_131024_87157.png', '18_131025_87157.png', '17_65513_43578.png', '18_131026_87156.png', '18_131027_87156.png', '18_131026_87157.png', '18_131027_87157.png', '17_65512_43579.png', '18_131024_87158.png', '18_131025_87158.png', '18_131024_87159.png', '18_131025_87159.png', '17_65513_43579.png', '18_131026_87158.png', '18_131027_87158.png', '18_131026_87159.png', '18_131027_87159.png', '16_32757_21789.png', '17_65514_43578.png', '18_131028_87156.png', '18_131029_87156.png', '18_131028_87157.png', '18_131029_87157.png', '17_65515_43578.png', '18_131030_87156.png', '18_131031_87156.png', '18_131030_87157.png', '18_131031_87157.png', '17_65514_43579.png', '18_131028_87158.png', '18_131029_87158.png', '18_131028_87159.png', '18_131029_87159.png', '17_65515_43579.png', '18_131030_87158.png', '18_131031_87158.png', '18_131030_87159.png', '18_131031_87159.png', '15_16379_10894.png', '16_32758_21788.png', '17_65516_43576.png', '18_131032_87152.png', '18_131033_87152.png', '18_131032_87153.png', '18_131033_87153.png', '17_65517_43576.png', '18_131034_87152.png', '18_131035_87152.png', '18_131034_87153.png', '18_131035_87153.png', '17_65516_43577.png', '18_131032_87154.png', '18_131033_87154.png', '18_131032_87155.png', '18_131033_87155.png', '17_65517_43577.png', '18_131034_87154.png', '18_131035_87154.png', '18_131034_87155.png', '18_131035_87155.png', '16_32759_21788.png', '17_65518_43576.png', '18_131036_87152.png', '18_131037_87152.png', '18_131036_87153.png', '18_131037_87153.png', '17_65519_43576.png', '18_131038_87152.png', '18_131039_87152.png', '18_131038_87153.png', '18_131039_87153.png', '17_65518_43577.png', '18_131036_87154.png', '18_131037_87154.png', '18_131036_87155.png', '18_131037_87155.png', '17_65519_43577.png', '18_131038_87154.png', '18_131039_87154.png', '18_131038_87155.png', '18_131039_87155.png', '16_32758_21789.png', '17_65516_43578.png', '18_131032_87156.png', '18_131033_87156.png', '18_131032_87157.png', '18_131033_87157.png', '17_65517_43578.png', '18_131034_87156.png', '18_131035_87156.png', '18_131034_87157.png', '18_131035_87157.png', '17_65516_43579.png', '18_131032_87158.png', '18_131033_87158.png', '18_131032_87159.png', '18_131033_87159.png', '17_65517_43579.png', '18_131034_87158.png', '18_131035_87158.png', '18_131034_87159.png', '18_131035_87159.png', '16_32759_21789.png', '17_65518_43578.png', '18_131036_87156.png', '18_131037_87156.png', '18_131036_87157.png', '18_131037_87157.png', '17_65519_43578.png', '18_131038_87156.png', '18_131039_87156.png', '18_131038_87157.png', '18_131039_87157.png', '17_65518_43579.png', '18_131036_87158.png', '18_131037_87158.png', '18_131036_87159.png', '18_131037_87159.png', '17_65519_43579.png', '18_131038_87158.png', '18_131039_87158.png', '18_131038_87159.png', '18_131039_87159.png', '15_16378_10895.png', '16_32756_21790.png', '17_65512_43580.png', '18_131024_87160.png', '18_131025_87160.png', '18_131024_87161.png', '18_131025_87161.png', '17_65513_43580.png', '18_131026_87160.png', '18_131027_87160.png', '18_131026_87161.png', '18_131027_87161.png', '17_65512_43581.png', '18_131024_87162.png', '18_131025_87162.png', '18_131024_87163.png', '18_131025_87163.png', '17_65513_43581.png', '18_131026_87162.png', '18_131027_87162.png', '18_131026_87163.png', '18_131027_87163.png', '16_32757_21790.png', '17_65514_43580.png', '18_131028_87160.png', '18_131029_87160.png', '18_131028_87161.png', '18_131029_87161.png', '17_65515_43580.png', '18_131030_87160.png', '18_131031_87160.png', '18_131030_87161.png', '18_131031_87161.png', '17_65514_43581.png', '18_131028_87162.png', '18_131029_87162.png', '18_131028_87163.png', '18_131029_87163.png', '17_65515_43581.png', '18_131030_87162.png', '18_131031_87162.png', '18_131030_87163.png', '18_131031_87163.png', '16_32756_21791.png', '17_65512_43582.png', '18_131024_87164.png', '18_131025_87164.png', '18_131024_87165.png', '18_131025_87165.png', '17_65513_43582.png', '18_131026_87164.png', '18_131027_87164.png', '18_131026_87165.png', '18_131027_87165.png', '17_65512_43583.png', '18_131024_87166.png', '18_131025_87166.png', '18_131024_87167.png', '18_131025_87167.png', '17_65513_43583.png', '18_131026_87166.png', '18_131027_87166.png', '18_131026_87167.png', '18_131027_87167.png', '16_32757_21791.png', '17_65514_43582.png', '18_131028_87164.png', '18_131029_87164.png', '18_131028_87165.png', '18_131029_87165.png', '17_65515_43582.png', '18_131030_87164.png', '18_131031_87164.png', '18_131030_87165.png', '18_131031_87165.png', '17_65514_43583.png', '18_131028_87166.png', '18_131029_87166.png', '18_131028_87167.png', '18_131029_87167.png', '17_65515_43583.png', '18_131030_87166.png', '18_131031_87166.png', '18_131030_87167.png', '18_131031_87167.png', '15_16379_10895.png', '16_32758_21790.png', '17_65516_43580.png', '18_131032_87160.png', '18_131033_87160.png', '18_131032_87161.png', '18_131033_87161.png', '17_65517_43580.png', '18_131034_87160.png', '18_131035_87160.png', '18_131034_87161.png', '18_131035_87161.png', '17_65516_43581.png', '18_131032_87162.png', '18_131033_87162.png', '18_131032_87163.png', '18_131033_87163.png', '17_65517_43581.png', '18_131034_87162.png', '18_131035_87162.png', '18_131034_87163.png', '18_131035_87163.png', '16_32759_21790.png', '17_65518_43580.png', '18_131036_87160.png', '18_131037_87160.png', '18_131036_87161.png', '18_131037_87161.png', '17_65519_43580.png', '18_131038_87160.png', '18_131039_87160.png', '18_131038_87161.png', '18_131039_87161.png', '17_65518_43581.png', '18_131036_87162.png', '18_131037_87162.png', '18_131036_87163.png', '18_131037_87163.png', '17_65519_43581.png', '18_131038_87162.png', '18_131039_87162.png', '18_131038_87163.png', '18_131039_87163.png', '16_32758_21791.png', '17_65516_43582.png', '18_131032_87164.png', '18_131033_87164.png', '18_131032_87165.png', '18_131033_87165.png', '17_65517_43582.png', '18_131034_87164.png', '18_131035_87164.png', '18_131034_87165.png', '18_131035_87165.png', '17_65516_43583.png', '18_131032_87166.png', '18_131033_87166.png', '18_131032_87167.png', '18_131033_87167.png', '17_65517_43583.png', '18_131034_87166.png', '18_131035_87166.png', '18_131034_87167.png', '18_131035_87167.png', '16_32759_21791.png', '17_65518_43582.png', '18_131036_87164.png', '18_131037_87164.png', '18_131036_87165.png', '18_131037_87165.png', '17_65519_43582.png', '18_131038_87164.png', '18_131039_87164.png', '18_131038_87165.png', '18_131039_87165.png', '17_65518_43583.png', '18_131036_87166.png', '18_131037_87166.png', '18_131036_87167.png', '18_131037_87167.png', '17_65519_43583.png', '18_131038_87166.png', '18_131039_87166.png', '18_131038_87167.png', '18_131039_87167.png']\n",
      "Min x: 131024, Max x: 131039, Min y: 87152, Max y: 87167\n"
     ]
    }
   ],
   "source": [
    "tilenames_list = get_filename_sub_tiles(FILENAME, 18)\n",
    "\n",
    "print(tilenames_list)\n",
    "\n",
    "def find_min_max(filenames, z_value):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    for filename in filenames:\n",
    "        parts = filename.split('_')\n",
    "        z = int(parts[0])\n",
    "        x = int(parts[1])\n",
    "        y = int(parts[2].split('.')[0])  # 注意这里我们需要去除文件扩展名\n",
    "        if z == z_value:\n",
    "            x_values.append(x)\n",
    "            y_values.append(y)\n",
    "    return min(x_values), max(x_values), min(y_values), max(y_values)\n",
    "\n",
    "# 假设你的文件名列表是 filenames\n",
    "min_x, max_x, min_y, max_y = find_min_max(tilenames_list, 18)\n",
    "\n",
    "print(f\"Min x: {min_x}, Max x: {max_x}, Min y: {min_y}, Max y: {max_y}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
